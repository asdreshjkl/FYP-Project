{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa7f0e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\VICTUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\VICTUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e109c669",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muslim and non-Muslim folks. What are your tho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It takes a lot of courage to end ur own life. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Those condemning the victims r bunch of low li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Depression is no joke. Get help, voice out, po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coming from an atheist with no in depth religi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Posts\n",
       "0  Muslim and non-Muslim folks. What are your tho...\n",
       "1  It takes a lot of courage to end ur own life. ...\n",
       "2  Those condemning the victims r bunch of low li...\n",
       "3  Depression is no joke. Get help, voice out, po...\n",
       "4  Coming from an atheist with no in depth religi..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/VICTUS/Documents/STIX 3913 Project 1/Excel Data/Reddit Posts.csv\", encoding='cp1252')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae66b708",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Posts</th>\n",
       "      <th>Lemmatize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muslim and non-Muslim folks. What are your tho...</td>\n",
       "      <td>muslim and non-muslim folks. what are your tho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It takes a lot of courage to end ur own life. ...</td>\n",
       "      <td>it takes a lot of courage to end ur own life. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Those condemning the victims r bunch of low li...</td>\n",
       "      <td>those condemning the victims r bunch of low li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Depression is no joke. Get help, voice out, po...</td>\n",
       "      <td>depression is no joke. get help, voice out, po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coming from an atheist with no in depth religi...</td>\n",
       "      <td>coming from an atheist with no in depth religi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Posts  \\\n",
       "0  Muslim and non-Muslim folks. What are your tho...   \n",
       "1  It takes a lot of courage to end ur own life. ...   \n",
       "2  Those condemning the victims r bunch of low li...   \n",
       "3  Depression is no joke. Get help, voice out, po...   \n",
       "4  Coming from an atheist with no in depth religi...   \n",
       "\n",
       "                                           Lemmatize  \n",
       "0  muslim and non-muslim folks. what are your tho...  \n",
       "1  it takes a lot of courage to end ur own life. ...  \n",
       "2  those condemning the victims r bunch of low li...  \n",
       "3  depression is no joke. get help, voice out, po...  \n",
       "4  coming from an atheist with no in depth religi...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lowercase\n",
    "df['Lemmatize'] = df['Posts'].map(lambda x: x if type(x)!=str else x.lower())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f6d3e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Posts</th>\n",
       "      <th>Lemmatize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muslim and non-Muslim folks. What are your tho...</td>\n",
       "      <td>muslim and nonmuslim folks what are your thoug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It takes a lot of courage to end ur own life. ...</td>\n",
       "      <td>it takes a lot of courage to end ur own life w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Those condemning the victims r bunch of low li...</td>\n",
       "      <td>those condemning the victims r bunch of low li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Depression is no joke. Get help, voice out, po...</td>\n",
       "      <td>depression is no joke get help voice out pour ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coming from an atheist with no in depth religi...</td>\n",
       "      <td>coming from an atheist with no in depth religi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Posts  \\\n",
       "0  Muslim and non-Muslim folks. What are your tho...   \n",
       "1  It takes a lot of courage to end ur own life. ...   \n",
       "2  Those condemning the victims r bunch of low li...   \n",
       "3  Depression is no joke. Get help, voice out, po...   \n",
       "4  Coming from an atheist with no in depth religi...   \n",
       "\n",
       "                                           Lemmatize  \n",
       "0  muslim and nonmuslim folks what are your thoug...  \n",
       "1  it takes a lot of courage to end ur own life w...  \n",
       "2  those condemning the victims r bunch of low li...  \n",
       "3  depression is no joke get help voice out pour ...  \n",
       "4  coming from an atheist with no in depth religi...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove number, puntuation, special character\n",
    "df['Lemmatize'] = df['Lemmatize'].str.replace('[^A-Za-z0-9 ]+', '', regex=True)\n",
    "\n",
    "#Removing urls\n",
    "df['Lemmatize'] = df['Lemmatize'].str.replace('http\\S+|www.\\S+', '', case=False, regex=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e9cf464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Posts</th>\n",
       "      <th>Lemmatize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muslim and non-Muslim folks. What are your tho...</td>\n",
       "      <td>muslim nonmuslim folks thoughts suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It takes a lot of courage to end ur own life. ...</td>\n",
       "      <td>takes lot courage end ur life dont know went c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Those condemning the victims r bunch of low li...</td>\n",
       "      <td>condemning victims r bunch low lives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Depression is no joke. Get help, voice out, po...</td>\n",
       "      <td>depression joke get help voice pour ur heart w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coming from an atheist with no in depth religi...</td>\n",
       "      <td>coming atheist depth religious knowledge suici...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Posts  \\\n",
       "0  Muslim and non-Muslim folks. What are your tho...   \n",
       "1  It takes a lot of courage to end ur own life. ...   \n",
       "2  Those condemning the victims r bunch of low li...   \n",
       "3  Depression is no joke. Get help, voice out, po...   \n",
       "4  Coming from an atheist with no in depth religi...   \n",
       "\n",
       "                                           Lemmatize  \n",
       "0            muslim nonmuslim folks thoughts suicide  \n",
       "1  takes lot courage end ur life dont know went c...  \n",
       "2               condemning victims r bunch low lives  \n",
       "3  depression joke get help voice pour ur heart w...  \n",
       "4  coming atheist depth religious knowledge suici...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "df['Lemmatize'] = df['Lemmatize'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c6d1b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Posts</th>\n",
       "      <th>Lemmatize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muslim and non-Muslim folks. What are your tho...</td>\n",
       "      <td>[muslim, nonmuslim, folks, thoughts, suicide]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It takes a lot of courage to end ur own life. ...</td>\n",
       "      <td>[takes, lot, courage, end, ur, life, dont, kno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Those condemning the victims r bunch of low li...</td>\n",
       "      <td>[condemning, victims, r, bunch, low, lives]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Depression is no joke. Get help, voice out, po...</td>\n",
       "      <td>[depression, joke, get, help, voice, pour, ur,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coming from an atheist with no in depth religi...</td>\n",
       "      <td>[coming, atheist, depth, religious, knowledge,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Posts  \\\n",
       "0  Muslim and non-Muslim folks. What are your tho...   \n",
       "1  It takes a lot of courage to end ur own life. ...   \n",
       "2  Those condemning the victims r bunch of low li...   \n",
       "3  Depression is no joke. Get help, voice out, po...   \n",
       "4  Coming from an atheist with no in depth religi...   \n",
       "\n",
       "                                           Lemmatize  \n",
       "0      [muslim, nonmuslim, folks, thoughts, suicide]  \n",
       "1  [takes, lot, courage, end, ur, life, dont, kno...  \n",
       "2        [condemning, victims, r, bunch, low, lives]  \n",
       "3  [depression, joke, get, help, voice, pour, ur,...  \n",
       "4  [coming, atheist, depth, religious, knowledge,...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = TweetTokenizer()\n",
    "df['Lemmatize'] = df['Lemmatize'].apply(tt.tokenize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f4b8b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Posts</th>\n",
       "      <th>Lemmatize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muslim and non-Muslim folks. What are your tho...</td>\n",
       "      <td>[muslim, nonmuslim, folk, thought, suicide]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It takes a lot of courage to end ur own life. ...</td>\n",
       "      <td>[take, lot, courage, end, ur, life, dont, know...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Those condemning the victims r bunch of low li...</td>\n",
       "      <td>[condemning, victim, r, bunch, low, life]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Depression is no joke. Get help, voice out, po...</td>\n",
       "      <td>[depression, joke, get, help, voice, pour, ur,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coming from an atheist with no in depth religi...</td>\n",
       "      <td>[coming, atheist, depth, religious, knowledge,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Posts  \\\n",
       "0  Muslim and non-Muslim folks. What are your tho...   \n",
       "1  It takes a lot of courage to end ur own life. ...   \n",
       "2  Those condemning the victims r bunch of low li...   \n",
       "3  Depression is no joke. Get help, voice out, po...   \n",
       "4  Coming from an atheist with no in depth religi...   \n",
       "\n",
       "                                           Lemmatize  \n",
       "0        [muslim, nonmuslim, folk, thought, suicide]  \n",
       "1  [take, lot, courage, end, ur, life, dont, know...  \n",
       "2          [condemning, victim, r, bunch, low, life]  \n",
       "3  [depression, joke, get, help, voice, pour, ur,...  \n",
       "4  [coming, atheist, depth, religious, knowledge,...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmtzr = WordNetLemmatizer()\n",
    "df['Lemmatize'] = df['Lemmatize'].apply(lambda lst:[lmtzr.lemmatize(word) for word in lst])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad2b31d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#porter = PorterStemmer()\n",
    "#df['Stemming'] = df['Stemming'].apply(lambda lst:[porter.stem(word) for word in lst])\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a82f8490",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:/Users/VICTUS/Documents/STIX 3913 Project 1/Excel Data/Preprocessed Data Lemmatize.csv\"\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623a02d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
